{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Assignment 4 BUDA 451\"\n",
        "author: \"Collin Edwards\"\n",
        "date: \"today\"\n",
        "format: pdf\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "## Question 1: Similarity and Distance\n",
        "\n",
        "### (a) Hamming Distance and Jaccard Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "# define the two binary vectors\n",
        "x = np.array([0,1,0,1,0,1,0,0,0,1])\n",
        "y = np.array([0,1,0,0,0,1,1,0,0,0])\n",
        "\n",
        "# (a) Hamming distance = number of positions where they differ\n",
        "hamming = np.sum(x != y)\n",
        "\n",
        "# (a) Jaccard similarity = |intersection| / |union|\n",
        "intersection = np.sum((x == 1) & (y == 1))\n",
        "union        = np.sum((x == 1) | (y == 1))\n",
        "jaccard = intersection / union if union else 0\n",
        "\n",
        "print(f\"Hamming distance: {hamming}\")\n",
        "print(f\"Jaccard similarity: {jaccard:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**(1b) Choice of Similarity Measure**\n",
        "\n",
        "For very sparse purchase-history vectors at Amazon, I prefer measures that *ignore double-zeros*, so that unpurchased items don’t dominate the similarity.\\\n",
        "- **Jaccard coefficient** (and similarly **Cosine similarity**) focus only on co-purchases (1’s), whereas Hamming or Simple Matching count zeros and can be misleading.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Question 2: k‑Means Clustering\n",
        "\n",
        "### (a) k‑Means Algorithm Description\n",
        "\n",
        "k-Means is an iterative algorithm for partitioning data into k clusters. It minimizes the within-cluster variance by: 1. Initialize K centroids randomly. 2. Assign each point to nearest centroid by Euclidean distance. 3. Update each centroid to the mean of its assigned points. 4. Repeat steps 2-3 until centroids stabilize.\n",
        "\n",
        "### (b) Identifying the k‑Means Output=\n",
        "\n",
        "**k‑means produces compact, roughly spherical clusters (Voronoi partitions).**\\\n",
        "- **Dataset A (two clusters):**\\\n",
        "- **A2** is k‑means (clusters are round and balanced).\\\n",
        "- A1 shows a non‑convex shape, which k‑means cannot capture.\\\n",
        "- **Dataset B (two clusters):**\\\n",
        "- **B1** is k‑means (clusters look round).\\\n",
        "- B2 has elongated shapes, not typical for k‑means.\\\n",
        "- **Dataset C (three clusters):**\\\n",
        "- **C1** is k‑means (three round, Ill‑separated groups).\\\n",
        "- C2 splits one natural group, which k‑means avoids when clusters are distinct.\n",
        "\n",
        "+--------------------------------------------------------------------------------------------------+\n",
        "| \\## Question 3: Hierarchical Clustering                                                          |\n",
        "+--------------------------------------------------------------------------------------------------+\n",
        "| I have clusters A and B, each with four 2‑D points. The Euclidean distance is\\                  |\n",
        "| $$ d(x,y)=\\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}. $$                                                     |\n",
        "+--------------------------------------------------------------------------------------------------+\n",
        "| \\- **Complete Link (farthest pair):**\\                                                           |\n",
        "| $$(\\displaystyle \\max\\_{a\\in A,b\\in B}d(a,b)\\approx2.1090)$$                                     |\n",
        "+--------------------------------------------------------------------------------------------------+\n",
        "| \\- **Single Link (closest pair):**\\                                                              |\n",
        "| $$(\\displaystyle \\min\\_{a\\in A,b\\in B}d(a,b)\\approx0.9220)$$                                     |\n",
        "+--------------------------------------------------------------------------------------------------+\n",
        "| \\- **Average Link (mean of all 16 distances):**\\                                                 |\n",
        "| $$\\frac1{16}\\sum_{a\\in A,b\\in B}d(a,b)\\approx1.4127)$$                                           |\n",
        "+--------------------------------------------------------------------------------------------------+\n",
        "| \\- **Centroid Link (distance betIen centroids):**\\                                              |\n",
        "| $$d(\\frac{1}{4}\\sum_{a\\in A}a,\\frac{1}{4}\\sum_{b\\in B}b)\\approx1.4142)$$                         |\n",
        "+--------------------------------------------------------------------------------------------------+\n",
        "| **Robustness to Noise:** - Single link can drop too low if one pair is accidentally very close.\\ |\n",
        "+--------------------------------------------------------------------------------------------------+\n",
        "| \\- Complete link can spike if one pair is an outlier.\\                                           |\n",
        "+--------------------------------------------------------------------------------------------------+\n",
        "| \\- **Average link** smooths out extremes and is the most robust.                                 |\n",
        "+--------------------------------------------------------------------------------------------------+\n",
        "\n",
        "## Question 4: Programming (USArrests)\n",
        "\n",
        "I load and normalize the USArrests data, perform K‑means, use the Elbow method, and build dendrograms for three linkage methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "\n",
        "\n",
        "\n",
        "# 1) Load the data\n",
        "url = \"https://raw.githubusercontent.com/binbenliu/Teaching/main/data/USArrests.txt\"\n",
        "df = pd.read_csv(url, index_col=0)\n",
        "\n",
        "# 2) Normalize the features\n",
        "features = [\"Murder\", \"Assault\", \"UrbanPop\", \"Rape\"]\n",
        "X = StandardScaler().fit_transform(df[features])\n",
        "\n",
        "# 3) K‑means with K=3 (just to show I can)\n",
        "k3 = KMeans(n_clusters=3, random_state=42).fit(X)\n",
        "\n",
        "# instead of print(...), do\n",
        "centers = pd.DataFrame(\n",
        "    k3.cluster_centers_,\n",
        "    columns=features\n",
        ")\n",
        "centers\n",
        "\n",
        "# 4) Compute inertias for K=1..10\n",
        "inertias = [KMeans(n_clusters=k, random_state=42).fit(X).inertia_\n",
        "            for k in range(1, 11)]\n",
        "\n",
        "# 5) Plot the Elbow curve and inset a small logo\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "ax.plot(range(1, 11), inertias, 'o-', linewidth=2, markersize=6)\n",
        "ax.set_xticks(range(1, 11))\n",
        "ax.set_xlabel(\"Number of clusters K\", fontsize=12)\n",
        "ax.set_ylabel(\"Inertia\", fontsize=12)\n",
        "ax.set_title(\"Elbow Method for USArrests Type Deal\", fontsize=14)\n",
        "ax.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# annotate the “elbow”\n",
        "opt_k = 4\n",
        "ax.annotate(\"Elbow\",\n",
        "            xy=(opt_k, inertias[opt_k-1]),\n",
        "            xytext=(opt_k+1, inertias[opt_k-1] + 23),\n",
        "            arrowprops=dict(arrowstyle='fancy', color='red'),\n",
        "            color='green')\n",
        "\n",
        "# ─── lines below are inserting the logo as a perfect circle ───\n",
        "\n",
        "# 1) load the logo\n",
        "img = mpimg.imread(\"images/logo1.png\")\n",
        "\n",
        "# 2) ensure RGBA\n",
        "h, w = img.shape[:2]\n",
        "if img.shape[2] == 3:\n",
        "    rgba = np.zeros((h, w, 4), dtype=img.dtype)\n",
        "    rgba[..., :3] = img\n",
        "    rgba[...,  3] = 255\n",
        "else:\n",
        "    rgba = img.copy()\n",
        "\n",
        "# 3) build a circular mask\n",
        "yy, xx = np.ogrid[:h, :w]\n",
        "cy, cx = h/2, w/2\n",
        "r = min(h, w) / 2\n",
        "mask = (yy - cy)**2 + (xx - cx)**2 <= r**2\n",
        "\n",
        "# 4) apply mask to alpha channel\n",
        "rgba[..., 3] = rgba[..., 3] * mask\n",
        "\n",
        "# 5) create and add the clipped image\n",
        "imagebox = OffsetImage(rgba, zoom=0.10)\n",
        "ab = AnnotationBbox(\n",
        "    imagebox,\n",
        "    (0.98, 0.98),\n",
        "    xycoords='axes fraction',\n",
        "    frameon=False\n",
        ")\n",
        "ax.add_artist(ab)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 6) Agglomerative clustering dendrograms\n",
        "\n",
        "# 1) Read the PNG\n",
        "logo = mpimg.imread(\"images/logo6.png\")\n",
        "h, w = logo.shape[:2]\n",
        "\n",
        "# 2) Ensure RGBA\n",
        "if logo.shape[2] == 3:\n",
        "    rgba = np.zeros((h, w, 4), dtype=logo.dtype)\n",
        "    rgba[...,:3] = logo\n",
        "    rgba[..., 3]  = 255\n",
        "else:\n",
        "    rgba = logo.copy()\n",
        "\n",
        "# 3) Build a circular mask\n",
        "yy, xx = np.ogrid[:h, :w]\n",
        "cy, cx = h/2, w/2\n",
        "r = min(h, w)/2\n",
        "mask = (yy - cy)**2 + (xx - cx)**2 <= r**2\n",
        "rgba[..., 3] *= mask  # mask alpha channel\n",
        "\n",
        "# ——————————————————————————\n",
        "\n",
        "for method in [\"single\", \"complete\", \"average\"]:\n",
        "    Z = linkage(X, method=method)\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "    dendrogram(Z, labels=df.index,\n",
        "               leaf_rotation=90, leaf_font_size=6,\n",
        "               ax=ax)\n",
        "    ax.set_title(f\"{method.title()} Linkage Dendrogram\", fontsize=12)\n",
        "    ax.set_xlabel(\"States\", fontsize=10)\n",
        "    ax.set_ylabel(\"Distance\", fontsize=10)\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.4)\n",
        "    \n",
        "    # — insert circular logo into this axes —\n",
        "    imagebox = OffsetImage(rgba, zoom=0.10)\n",
        "    ab = AnnotationBbox(\n",
        "        imagebox,\n",
        "        (1, 0.99),            # top‑right in axes fraction coords\n",
        "        xycoords='axes fraction',\n",
        "        frameon=False\n",
        "    )\n",
        "    ax.add_artist(ab)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Illustrated above are the dendrograms for the three linkage methods: single, complete, and average. Each dendrogram shows how the states cluster based on their arrest rate. It's important to note that the choice of linkage method can significantly affect the clustering results, as seen in the different shapes and heights of the branches in each dendrogram."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/collinedwards/.virtualenvs/r-reticulate/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}